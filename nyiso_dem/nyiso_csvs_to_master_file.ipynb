{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "Some files are missing entries\n",
    "* Empty rows are being added\n",
    "* 2003 is an especially bad year for gaps\n",
    "* Will use 2004-2019 for analysis\n",
    "* 2004 has many duplicate entries, they appear to follow the few % difference style of 2005\n",
    "\n",
    "# FIXME\n",
    "Some files have multiple entries for a single region for a given time stamp\n",
    "* Currently, I am taking the first entry\n",
    "* Email NYISO about best idea\n",
    "* Check to see % difference in the two values\n",
    "\n",
    "Some files are missing entries\n",
    "* Still need to fill in values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get UTC from local and DST\n",
    "def to_utc_dt(date_time, time_zone):\n",
    "    local = pytz.timezone ('US/Eastern')\n",
    "    naive = datetime.strptime(date_time, '%m/%d/%Y %H:%M:%S')\n",
    "    if time_zone == 'EST': # Eastern Standard Time\n",
    "        is_dst_now = False\n",
    "    if time_zone == 'EDT': # Eastern Daylight Time\n",
    "        is_dst_now = True\n",
    "    local_dt = local.localize(naive, is_dst=is_dst_now)\n",
    "    utc_dt = local_dt.astimezone(pytz.utc)\n",
    "\n",
    "    return utc_dt\n",
    "\n",
    "def get_files(year, month):\n",
    "    files = glob(f'./nyiso_{year}{month:02}/{year}*.csv')\n",
    "    files.sort()\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        #print(f)\n",
    "        df = nyiso_to_neat_data(f)\n",
    "        if type(df) == int:\n",
    "            continue\n",
    "        else:\n",
    "            dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "def nyiso_to_neat_data(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    #print(df.head())\n",
    "    #print(df.tail())\n",
    "    mapping = {}\n",
    "    mapping['date_time'] = []\n",
    "    mapping['old_date_time'] = []\n",
    "    mapping['time_zone'] = []\n",
    "    # Get all regions\n",
    "    # Some data issues lead to regions having multiple entries\n",
    "    # in first hour\n",
    "    start_time = -1\n",
    "    for idx in df.index:\n",
    "        utc_dt = to_utc_dt(df.loc[idx, 'Time Stamp'], df.loc[idx, 'Time Zone'])\n",
    "        if start_time == -1:\n",
    "            start_time = utc_dt\n",
    "        if utc_dt != start_time:\n",
    "            break\n",
    "        if df.loc[idx, 'Name'] not in mapping.keys():\n",
    "            mapping[df.loc[idx, 'Name']] = []\n",
    "    #print(mapping)\n",
    "    # Populate values\n",
    "    for idx in df.index:\n",
    "        utc_dt = to_utc_dt(df.loc[idx, 'Time Stamp'], df.loc[idx, 'Time Zone'])\n",
    "        if utc_dt not in mapping['date_time']:\n",
    "            mapping['date_time'].append(utc_dt)\n",
    "            mapping['old_date_time'].append(df.loc[idx, 'Time Stamp'])\n",
    "            mapping['time_zone'].append(df.loc[idx, 'Time Zone'])\n",
    "        \n",
    "        # DUPLICATE ENTRIES\n",
    "        # Lots of duplicates in 2004 - have not checked them, will likely skip that year\n",
    "        # The four cases in 2005 have ~ identical values, so avg them\n",
    "        # The three cases in 2006,2007,2008 have zero entries as one version, so take non-zero one\n",
    "        if len(mapping['date_time']) == len(mapping[df.loc[idx, 'Name']]):\n",
    "            print(f\"Duplicate region entry for {df.loc[idx, 'Name']} at {df.loc[idx, 'Time Stamp']}\")\n",
    "            # if new values is zero, continue\n",
    "            if df.loc[idx, 'Integrated Load'] == 0:\n",
    "                print(f\" --- Duplicate with second value as zero {df.loc[idx, 'Name']}, skip\")\n",
    "            # if previous value was zero, replace\n",
    "            elif mapping[df.loc[idx, 'Name']][-1] == 0:\n",
    "                print(f\" --- Duplicate with initial value as zero, replace with {df.loc[idx, 'Integrated Load']}.\")\n",
    "                mapping[df.loc[idx, 'Name']][-1] = df.loc[idx, 'Integrated Load']\n",
    "            # else, avg them\n",
    "            else:\n",
    "                print(f\" --- Duplicate, averaging {mapping[df.loc[idx, 'Name']][-1]} with {df.loc[idx, 'Integrated Load']}.\")\n",
    "                print(f\" -------------------------------------------- {mapping[df.loc[idx, 'Name']][-1]} / {df.loc[idx, 'Integrated Load']} = {mapping[df.loc[idx, 'Name']][-1] / df.loc[idx, 'Integrated Load']}\")\n",
    "                mapping[df.loc[idx, 'Name']][-1] = (mapping[df.loc[idx, 'Name']][-1] + df.loc[idx, 'Integrated Load'])/2\n",
    "                   \n",
    "        if len(mapping['date_time']) == len(mapping[df.loc[idx, 'Name']]) + 1:\n",
    "            mapping[df.loc[idx, 'Name']].append(df.loc[idx, 'Integrated Load'])\n",
    "    #tgt_len = 24\n",
    "    #for k, v in mapping.items():\n",
    "    #    if len(v) != tgt_len:\n",
    "    #        print(f\"Length problem with file {fname}\")\n",
    "    #        print(k, len(v))\n",
    "    #        return -1\n",
    "    df_new = pd.DataFrame(mapping)\n",
    "    df_new = sum_ny_state(df_new)\n",
    "    return df_new\n",
    "\n",
    "def monthly_file(year, month):\n",
    "    dfs = get_files(year, month)\n",
    "    master = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        master = master.append(dfs[i], ignore_index = True)\n",
    "    #print(len(master.index))\n",
    "    master.to_csv(f'./nyiso_{year}{month:02}/demand_summary.csv', index=False)\n",
    "\n",
    "def sum_ny_state(df):\n",
    "    regions = df.columns.tolist()\n",
    "    regions.remove('date_time')\n",
    "    regions.remove('old_date_time')\n",
    "    regions.remove('time_zone')\n",
    "    ny_state = np.zeros(len(df.index))\n",
    "    for region in regions:\n",
    "        ny_state += df[region]\n",
    "    return_df = pd.DataFrame({\n",
    "        'date_time':df['date_time'],\n",
    "        'old_date_time':df['old_date_time'],\n",
    "        'time_zone':df['time_zone'],\n",
    "        'nyiso demand (MW)':ny_state\n",
    "    })\n",
    "    return return_df\n",
    "    \n",
    "def annual_file(year):\n",
    "    for month in range(1, 13):\n",
    "        df = pd.read_csv(f'./nyiso_{year}{month:02}/demand_summary.csv')\n",
    "        df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "        if month == 1:\n",
    "            master = df\n",
    "        else:\n",
    "            master = master.append(df, ignore_index = True)\n",
    "    \n",
    "    # Check for missing hours and insert them if needed\n",
    "    dt_to_add = []\n",
    "    start = master.iloc[0]['date_time']\n",
    "    prev = start\n",
    "    for idx in master.index:\n",
    "        crnt = master.loc[idx, 'date_time']\n",
    "        if crnt == start:\n",
    "            continue\n",
    "        # Check if sequential\n",
    "        if crnt != prev + timedelta(hours=1):\n",
    "            #print(f\"Missing data between previous {prev} and idx {idx} dt {crnt}.  Adding an empty row.\")\n",
    "            dt_to_add.append(prev + timedelta(hours=1))\n",
    "            \n",
    "            # Add hours until gap is filled\n",
    "            if crnt != prev + timedelta(hours=2):\n",
    "                n_hours = 2\n",
    "                while True:\n",
    "                    if crnt != prev + timedelta(hours=n_hours):\n",
    "                        #print(f\"Need visual inspection for idx {idx} year {year}\")\n",
    "                        dt_to_add.append(prev + timedelta(hours=n_hours))\n",
    "                        n_hours += 1\n",
    "                    else:\n",
    "                        print(f\"Total gap length: {n_hours-1} around {crnt}\")\n",
    "                        break\n",
    "        prev = crnt\n",
    "    print(f\"dts to add: {dt_to_add}\")\n",
    "    to_add = {}\n",
    "    for col in master.columns:\n",
    "        if col == 'date_time':\n",
    "            to_add[col] = dt_to_add\n",
    "        else:\n",
    "            to_add[col] = [np.nan for _ in range(len(dt_to_add))]\n",
    "    master = master.append(pd.DataFrame(to_add), ignore_index = True)\n",
    "    master = master.sort_values(['date_time'], ascending = True)\n",
    "        \n",
    "    print(f\"Length for year {year}: {len(master.index)}\")\n",
    "    master.to_csv(f'./demand_summary_{year}.csv', index=False, na_rep='NA')\n",
    "\n",
    "# Full range of available data\n",
    "#for year in range(2002, 2020):\n",
    "\n",
    "# 2009 onwards has zero gaps (may have multiple entries for a single hour, will check)\n",
    "for year in range(2004, 2009):\n",
    "    for month in range(1, 13):\n",
    "        print(year,month)\n",
    "        monthly_file(year, month)\n",
    "    annual_file(year)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
